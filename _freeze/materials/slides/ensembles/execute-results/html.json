{
  "hash": "49a99015fec3149abd77b74e49e62c4e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Tree-based and ensemble models\"\nformat:\n  revealjs:\n    slide-number: true\n    slide-level: 4\n    smaller: true\n    theme: [default, styles.scss]\n    incremental: true\njupyter: python3\nexecute:\n  echo: true\n  warning: false\n---\n\n\n## Tree-based methods\n\n- Algorithms that stratifying or segmenting the predictor space\n  into a number of simple regions.\n\n- We call these algorithms decision-tree methods\n because the decisions used to segment the predictor space\n can be summarized in a tree.\n\n- Decision trees on their own, are very explainable and intuitive,\n  but not very powerful at predicting.\n\n- However, there are extensions of decision trees,\n  such as random forest and boosted trees,\n  which are very powerful at predicting.\n  We will demonstrate two of these in this session.\n\n## Decision trees\n\n::: {.nonincremental}\n- [Decision Trees](https://mlu-explain.github.io/decision-tree/)\n  by Jared Wilber & Lucía Santamaría\n:::\n\n## Classification Decision trees\n\n- Use recursive binary splitting to grow a classification tree\n  (splitting of the predictor space into $J$ distinct, non-overlapping regions).\n\n-  For every observation that falls into the region $R_j$ ,\n  we make the same prediction,\n  which is the majority vote for the training observations in $R_j$.\n\n- Where to split the predictor space is done in a top-down and greedy manner,\n  and in practice for classification, the best split at any point in the algorithm\n  is one that minimizes the Gini index (a measure of node purity).\n\n- Decision trees are useful because they are very interpretable.\n\n- A limitation of decision trees is that theyn tend to overfit,\n  so in practice we use cross-validation to tune a hyperparameter,\n  $\\alpha$, to find the optimal, pruned tree.\n\n## Example: the heart data set\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.nonincremental}\n- Let's consider a situation where we'd like to be able to predict\n  the presence of heart disease (`AHD`) in patients,\n  based off 13 measured characteristics.\n\n- The [heart data set](https://www.statlearning.com/s/Heart.csv)\n  contains a binary outcome for heart disease\n  for patients who presented with chest pain.\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#00441400 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nheart = pd.read_csv(\"data/Heart.csv\", index_col=0)\nheart.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nIndex: 303 entries, 1 to 303\nData columns (total 14 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Age        303 non-null    int64  \n 1   Sex        303 non-null    int64  \n 2   ChestPain  303 non-null    object \n 3   RestBP     303 non-null    int64  \n 4   Chol       303 non-null    int64  \n 5   Fbs        303 non-null    int64  \n 6   RestECG    303 non-null    int64  \n 7   MaxHR      303 non-null    int64  \n 8   ExAng      303 non-null    int64  \n 9   Oldpeak    303 non-null    float64\n 10  Slope      303 non-null    int64  \n 11  Ca         299 non-null    float64\n 12  Thal       301 non-null    object \n 13  AHD        303 non-null    object \ndtypes: float64(2), int64(9), object(3)\nmemory usage: 35.5+ KB\n```\n:::\n:::\n\n\n:::\n::::\n\n## Example: the heart data set\n\nAn angiographic test was performed and a label for `AHD` of Yes\nwas labelled to indicate the presence of heart disease,\notherwise the label was No.\n\n::: {#92d9601c .cell execution_count=3}\n``` {.python .cell-code}\nheart.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPain</th>\n      <th>RestBP</th>\n      <th>Chol</th>\n      <th>Fbs</th>\n      <th>RestECG</th>\n      <th>MaxHR</th>\n      <th>ExAng</th>\n      <th>Oldpeak</th>\n      <th>Slope</th>\n      <th>Ca</th>\n      <th>Thal</th>\n      <th>AHD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>63</td>\n      <td>1</td>\n      <td>typical</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>2</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>fixed</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>1</td>\n      <td>asymptomatic</td>\n      <td>160</td>\n      <td>286</td>\n      <td>0</td>\n      <td>2</td>\n      <td>108</td>\n      <td>1</td>\n      <td>1.5</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>normal</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>67</td>\n      <td>1</td>\n      <td>asymptomatic</td>\n      <td>120</td>\n      <td>229</td>\n      <td>0</td>\n      <td>2</td>\n      <td>129</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>reversable</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37</td>\n      <td>1</td>\n      <td>nonanginal</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>0</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>normal</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>41</td>\n      <td>0</td>\n      <td>nontypical</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>2</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>normal</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Do we have a class imbalance?\n\nIt's always important to check this, as it may impact your splitting\nand/or modeling decisions.\n\n::: {#6e887fa4 .cell execution_count=4}\n``` {.python .cell-code}\nheart['AHD'].value_counts(normalize=True)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nAHD\nNo     0.541254\nYes    0.458746\nName: proportion, dtype: float64\n```\n:::\n:::\n\n\nThis looks pretty good!\nWe can move forward this time without doing much more about this.\n\n## Data splitting\n\nLet's split the data into training and test sets:\n\n::: {#fdb8a932 .cell execution_count=5}\n``` {.python .cell-code}\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nnp.random.seed(2024)\n\nheart_train, heart_test = train_test_split(\n    heart, train_size=0.8, stratify=heart[\"AHD\"]\n)\n\nX_train = heart_train.drop(columns=['AHD'])\ny_train = heart_train['AHD']\nX_test = heart_test.drop(columns=['AHD'])\ny_test = heart_test['AHD']\n```\n:::\n\n\n## Categorical variables\n\n:::: {.columns}\n::: {.column width=\"35%\"}\n::: {.nonincremental}\n- This is our first case of seeing categorical predictor variables,\ncan we treat them the same as numerical ones? **No!**\n\n- In `scikit-learn` we must perform **one-hot encoding**\n:::\n:::\n\n::: {.column width=\"65%\"}\n![](img/ensembles/onehot1-1-1.png)\n\n*Source: <https://scales.arabpsychology.com/stats/how-can-i-perform-one-hot-encoding-in-r/>*\n:::\n::::\n\n\n## Look at the data again\n\nWhich columns do we need to standardize?\n\nWhich do we need to one-hot encode?\n\n::: {#498c06b6 .cell execution_count=6}\n``` {.python .cell-code}\nheart.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPain</th>\n      <th>RestBP</th>\n      <th>Chol</th>\n      <th>Fbs</th>\n      <th>RestECG</th>\n      <th>MaxHR</th>\n      <th>ExAng</th>\n      <th>Oldpeak</th>\n      <th>Slope</th>\n      <th>Ca</th>\n      <th>Thal</th>\n      <th>AHD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>63</td>\n      <td>1</td>\n      <td>typical</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>2</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>fixed</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>1</td>\n      <td>asymptomatic</td>\n      <td>160</td>\n      <td>286</td>\n      <td>0</td>\n      <td>2</td>\n      <td>108</td>\n      <td>1</td>\n      <td>1.5</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>normal</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>67</td>\n      <td>1</td>\n      <td>asymptomatic</td>\n      <td>120</td>\n      <td>229</td>\n      <td>0</td>\n      <td>2</td>\n      <td>129</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>reversable</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37</td>\n      <td>1</td>\n      <td>nonanginal</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>0</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>normal</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>41</td>\n      <td>0</td>\n      <td>nontypical</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>2</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>normal</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## One hot encoding & pre-processing\n\n::: {#cc367d61 .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer, make_column_selector\n\nnumeric_feats = ['Age', 'RestBP', 'Chol', 'RestECG', 'MaxHR', 'Oldpeak','Slope', 'Ca']\npassthrough_feats = ['Sex', 'Fbs', 'ExAng']\ncategorical_feats = ['ChestPain', 'Thal']\n\nheart_preprocessor = make_column_transformer(\n    (StandardScaler(), numeric_feats),\n    (\"passthrough\", passthrough_feats),\n    (OneHotEncoder(handle_unknown = \"ignore\"), categorical_feats),\n)\n```\n:::\n\n\n> `handle_unknown = \"ignore\"` handles the case where\n> categories exist in the test data, which were missing in the training set.\n> Specifically, it sets the value for those to 0 for all cases of the category.\n\n## Fitting a dummy classifier\n\n::: {#97fcb8ad .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_validate\n\ndummy = DummyClassifier()\ndummy_pipeline = make_pipeline(heart_preprocessor, dummy)\ncv_10_dummy = pd.DataFrame(\n    cross_validate(\n        estimator=dummy_pipeline,\n        cv=10,\n        X=X_train,\n        y=y_train\n    )\n)\ncv_10_dummy_metrics = cv_10_dummy.agg([\"mean\", \"sem\"])\nresults = pd.DataFrame({'mean' : [cv_10_dummy_metrics.test_score.iloc[0]],\n  'sem' : [cv_10_dummy_metrics.test_score.iloc[1]]},\n  index = ['Dummy classifier']\n)\nresults\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Dummy classifier</th>\n      <td>0.541333</td>\n      <td>0.00299</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Fitting a decision tree\n\n::: {#bd1c4fe2 .cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier(random_state=2026)\n\ndt_pipeline = make_pipeline(heart_preprocessor, decision_tree)\ncv_10_dt = pd.DataFrame(\n    cross_validate(\n        estimator=dt_pipeline,\n        cv=10,\n        X=X_train,\n        y=y_train\n    )\n)\ncv_10_dt_metrics = cv_10_dt.agg([\"mean\", \"sem\"])\nresults_dt = pd.DataFrame({'mean' : [cv_10_dt_metrics.test_score.iloc[0]],\n  'sem' : [cv_10_dt_metrics.test_score.iloc[1]]},\n  index = ['Decision tree']\n)\nresults = pd.concat([results, results_dt])\nresults\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Dummy classifier</th>\n      <td>0.541333</td>\n      <td>0.00299</td>\n    </tr>\n    <tr>\n      <th>Decision tree</th>\n      <td>0.769167</td>\n      <td>0.02632</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Can we do better?\n\n- We could tune some decision tree parameters\n  (e.g., alpha, maximum tree depth, etc)...\n\n- We could also try a different tree-based method!\n\n- [The Random Forest Algorithm](https://mlu-explain.github.io/random-forest/)\n  by Jenny Yeon & Jared Wilber\n\n## The Random Forest Algorithm\n\n1. Build a number of decision trees on bootstrapped training samples.\n\n2. When building the trees from the bootstrapped samples,\n  at each stage of splitting,\n  the best splitting is computed using a randomly selected subset of the features.\n\n3. Take the majority votes across all the trees for the final prediction.\n\n## Random forest in `scikit-learn` & missing values\n\n:::: {.columns}\n::: {.column width=\"35%\"}\n::: {.nonincremental}\n- Does not accept missing values, we need to deal with these somehow...\n\n- We can either drop the observations with missing values,\n  or we can somehow impute them.\n\n- For the purposes of this demo we will drop them,\n  but if you are interested in imputation,\n  see the imputation tutorial in\n  [`scikit-learn`](https://scikit-learn.org/stable/modules/impute.html)\n:::\n:::\n\n::: {.column width=\"50%\"}\nHow many rows have missing observations:\n\n::: {#55ae6b4a .cell execution_count=10}\n``` {.python .cell-code}\nheart.isna().any(axis=1).sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n6\n```\n:::\n:::\n\n\nDrop rows with missing observations:\n\n::: {#9702abda .cell execution_count=11}\n``` {.python .cell-code}\nheart_train_drop_na = heart_train.dropna()\n\nX_train_drop_na = heart_train_drop_na.drop(\n    columns=['AHD']\n)\ny_train_drop_na = heart_train_drop_na['AHD']\n```\n:::\n\n\n:::\n::::\n\n## Random forest in `scikit-learn`\n\n::: {#e5b220f6 .cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(random_state=2026)\nrf_pipeline = make_pipeline(heart_preprocessor, random_forest)\ncv_10_rf = pd.DataFrame(\n    cross_validate(\n        estimator=rf_pipeline,\n        cv=10,\n        X=X_train_drop_na,\n        y=y_train_drop_na\n    )\n)\n\ncv_10_rf_metrics = cv_10_rf.agg([\"mean\", \"sem\"])\nresults_rf = pd.DataFrame({'mean' : [cv_10_rf_metrics.test_score.iloc[0]],\n  'sem' : [cv_10_rf_metrics.test_score.iloc[1]]},\n  index = ['Random forest']\n)\nresults = pd.concat([results, results_rf])\nresults\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Dummy classifier</th>\n      <td>0.541333</td>\n      <td>0.002990</td>\n    </tr>\n    <tr>\n      <th>Decision tree</th>\n      <td>0.769167</td>\n      <td>0.026320</td>\n    </tr>\n    <tr>\n      <th>Random forest</th>\n      <td>0.818297</td>\n      <td>0.017362</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Can we do better?\n\n- Random forest can be tuned a several important parameters, including:\n\n  - `n_estimators`: number of decision trees (higher = more complexity)\n\n  - `max_depth`: max depth of each decision tree (higher = more complexity)\n\n  - `max_features`: the number of features you get to look at each split\n  (higher = more complexity)\n\n- We can use `GridSearchCV` to search for the optimal parameters for these,\n  as we did for $K$ in $K$-nearest neighbors.\n\n## Tuning random forest in `scikit-learn`\n\n::: {#05383d97 .cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\n\nrf_param_grid = {'randomforestclassifier__n_estimators': [200],\n              'randomforestclassifier__max_depth': [1, 3, 5, 7, 9],\n              'randomforestclassifier__max_features': [1, 2, 3, 4, 5, 6, 7]}\n\nrf_tune_grid = GridSearchCV(\n    estimator=rf_pipeline,\n    param_grid=rf_param_grid,\n    cv=10,\n    n_jobs=-1 # tells computer to use all available CPUs\n)\nrf_tune_grid.fit(\n    X_train_drop_na,\n    y_train_drop_na\n)\n\ncv_10_rf_tuned_metrics = pd.DataFrame(rf_tune_grid.cv_results_)\nresults_rf_tuned = pd.DataFrame({'mean' : rf_tune_grid.best_score_,\n  'sem' : pd.DataFrame(rf_tune_grid.cv_results_)['std_test_score'][6] / 10**(1/2)},\n  index = ['Random forest tuned']\n)\nresults = pd.concat([results, results_rf_tuned])\n```\n:::\n\n\n## Random Forest results\n\nHow did the Random Forest compare\nagainst the other models we tried?\n\n::: {#aeca0c27 .cell execution_count=14}\n``` {.python .cell-code}\nresults\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Dummy classifier</th>\n      <td>0.541333</td>\n      <td>0.002990</td>\n    </tr>\n    <tr>\n      <th>Decision tree</th>\n      <td>0.769167</td>\n      <td>0.026320</td>\n    </tr>\n    <tr>\n      <th>Random forest</th>\n      <td>0.818297</td>\n      <td>0.017362</td>\n    </tr>\n    <tr>\n      <th>Random forest tuned</th>\n      <td>0.860688</td>\n      <td>0.022223</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Boosting\n\n- No randomization.\n\n- The key idea is combining many simple models called weak learners,\n  to create a strong learner.\n\n- They combine multiple shallow (depth 1 to 5) decision trees.\n\n- They build trees in a serial manner,\n  where each tree tries to correct the mistakes of the previous one.\n\n## Tuning `GradientBoostingClassifier` with `scikit-learn`\n\n- `GradientBoostingClassifier` can be tuned a several important parameters, including:\n\n  - `n_estimators`: number of decision trees (higher = more complexity)\n\n  - `max_depth`: max depth of each decision tree (higher = more complexity)\n\n  - `learning_rate`: the shrinkage parameter which controls the rate\n  at which boosting learns. Values between 0.01 or 0.001 are typical.\n\n- We can use `GridSearchCV` to search for the optimal parameters for these,\n  as we did for the parameters in Random Forest.\n\n## Tuning `GradientBoostingClassifier` with `scikit-learn`\n\n::: {#9ff241dd .cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngradient_boosted_classifier = GradientBoostingClassifier(random_state=2026)\ngb_pipeline = make_pipeline(heart_preprocessor, gradient_boosted_classifier)\ngb_param_grid = {'gradientboostingclassifier__n_estimators': [200],\n              'gradientboostingclassifier__max_depth': [1, 3, 5, 7, 9],\n              'gradientboostingclassifier__learning_rate': [0.001, 0.005, 0.01]}\ngb_tune_grid = GridSearchCV(\n    estimator=gb_pipeline,\n    param_grid=gb_param_grid,\n    cv=10,\n    n_jobs=-1 # tells computer to use all available CPUs\n)\ngb_tune_grid.fit(\n    X_train_drop_na,\n    y_train_drop_na\n)\n\ncv_10_gb_tuned_metrics = pd.DataFrame(gb_tune_grid.cv_results_)\nresults_gb_tuned = pd.DataFrame({'mean' : gb_tune_grid.best_score_,\n  'sem' : pd.DataFrame(gb_tune_grid.cv_results_)['std_test_score'][6] / 10**(1/2)},\n  index = ['Gradient boosted classifier tuned']\n)\nresults = pd.concat([results, results_gb_tuned])\n```\n:::\n\n\n## `GradientBoostingClassifier` results\n\nHow did the `GradientBoostingClassifier` compare\nagainst the other models we tried?\n\n::: {#2ca90dc4 .cell execution_count=16}\n``` {.python .cell-code}\nresults\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Dummy classifier</th>\n      <td>0.541333</td>\n      <td>0.002990</td>\n    </tr>\n    <tr>\n      <th>Decision tree</th>\n      <td>0.769167</td>\n      <td>0.026320</td>\n    </tr>\n    <tr>\n      <th>Random forest</th>\n      <td>0.818297</td>\n      <td>0.017362</td>\n    </tr>\n    <tr>\n      <th>Random forest tuned</th>\n      <td>0.860688</td>\n      <td>0.022223</td>\n    </tr>\n    <tr>\n      <th>Gradient boosted classifier tuned</th>\n      <td>0.851993</td>\n      <td>0.025671</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## How do we choose the final model?\n\n- Remember, what is your question or application?\n\n- A good rule when models are not very different,\n  what is the simplest model that does well?\n\n- Look at other metrics that are important to you\n  (not just the metric you used for tuning your model),\n  remember precision & recall, for example.\n\n- Remember - no peaking at the test set until you choose!\n  And then, you should only look at the test set for one model!\n\n## Precision and recall on the tuned random forest model\n\n::: {#9c01e456 .cell execution_count=17}\n``` {.python .cell-code}\nfrom sklearn.metrics import make_scorer, precision_score, recall_score\n\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': make_scorer(precision_score, pos_label='Yes'),\n    'recall': make_scorer(recall_score, pos_label='Yes')\n}\n\nrf_tune_grid = GridSearchCV(\n    estimator=rf_pipeline,\n    param_grid=rf_param_grid,\n    cv=10,\n    n_jobs=-1,\n    scoring=scoring,\n    refit='accuracy'\n)\n\nrf_tune_grid.fit(X_train_drop_na, y_train_drop_na)\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-1 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n                                        ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;,\n                                                                         StandardScaler(),\n                                                                         [&#x27;Age&#x27;,\n                                                                          &#x27;RestBP&#x27;,\n                                                                          &#x27;Chol&#x27;,\n                                                                          &#x27;RestECG&#x27;,\n                                                                          &#x27;MaxHR&#x27;,\n                                                                          &#x27;Oldpeak&#x27;,\n                                                                          &#x27;Slope&#x27;,\n                                                                          &#x27;Ca&#x27;]),\n                                                                        (&#x27;passthrough&#x27;,\n                                                                         &#x27;passthrough&#x27;,\n                                                                         [&#x27;Sex&#x27;,\n                                                                          &#x27;Fbs&#x27;,\n                                                                          &#x27;ExAng&#x27;]),\n                                                                        (&#x27;onehotencoder&#x27;,\n                                                                         OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n                                                                         [&#x27;ChestPain&#x27;,\n                                                                          &#x27;Thal&#x27;])])),\n                                       (&#x27;randomforestclas...\n             param_grid={&#x27;randomforestclassifier__max_depth&#x27;: [1, 3, 5, 7, 9],\n                         &#x27;randomforestclassifier__max_features&#x27;: [1, 2, 3, 4, 5,\n                                                                  6, 7],\n                         &#x27;randomforestclassifier__n_estimators&#x27;: [200]},\n             refit=&#x27;accuracy&#x27;,\n             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n                      &#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;, pos_label=Yes),\n                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;, pos_label=Yes)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=10,\n             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n                                        ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;,\n                                                                         StandardScaler(),\n                                                                         [&#x27;Age&#x27;,\n                                                                          &#x27;RestBP&#x27;,\n                                                                          &#x27;Chol&#x27;,\n                                                                          &#x27;RestECG&#x27;,\n                                                                          &#x27;MaxHR&#x27;,\n                                                                          &#x27;Oldpeak&#x27;,\n                                                                          &#x27;Slope&#x27;,\n                                                                          &#x27;Ca&#x27;]),\n                                                                        (&#x27;passthrough&#x27;,\n                                                                         &#x27;passthrough&#x27;,\n                                                                         [&#x27;Sex&#x27;,\n                                                                          &#x27;Fbs&#x27;,\n                                                                          &#x27;ExAng&#x27;]),\n                                                                        (&#x27;onehotencoder&#x27;,\n                                                                         OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n                                                                         [&#x27;ChestPain&#x27;,\n                                                                          &#x27;Thal&#x27;])])),\n                                       (&#x27;randomforestclas...\n             param_grid={&#x27;randomforestclassifier__max_depth&#x27;: [1, 3, 5, 7, 9],\n                         &#x27;randomforestclassifier__max_features&#x27;: [1, 2, 3, 4, 5,\n                                                                  6, 7],\n                         &#x27;randomforestclassifier__n_estimators&#x27;: [200]},\n             refit=&#x27;accuracy&#x27;,\n             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n                      &#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;, pos_label=Yes),\n                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;, pos_label=Yes)})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;,\n                                                  StandardScaler(),\n                                                  [&#x27;Age&#x27;, &#x27;RestBP&#x27;, &#x27;Chol&#x27;,\n                                                   &#x27;RestECG&#x27;, &#x27;MaxHR&#x27;,\n                                                   &#x27;Oldpeak&#x27;, &#x27;Slope&#x27;, &#x27;Ca&#x27;]),\n                                                 (&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,\n                                                  [&#x27;Sex&#x27;, &#x27;Fbs&#x27;, &#x27;ExAng&#x27;]),\n                                                 (&#x27;onehotencoder&#x27;,\n                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n                                                  [&#x27;ChestPain&#x27;, &#x27;Thal&#x27;])])),\n                (&#x27;randomforestclassifier&#x27;,\n                 RandomForestClassifier(max_depth=1, max_features=2,\n                                        n_estimators=200, random_state=2026))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>columntransformer: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for columntransformer: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;, StandardScaler(),\n                                 [&#x27;Age&#x27;, &#x27;RestBP&#x27;, &#x27;Chol&#x27;, &#x27;RestECG&#x27;, &#x27;MaxHR&#x27;,\n                                  &#x27;Oldpeak&#x27;, &#x27;Slope&#x27;, &#x27;Ca&#x27;]),\n                                (&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,\n                                 [&#x27;Sex&#x27;, &#x27;Fbs&#x27;, &#x27;ExAng&#x27;]),\n                                (&#x27;onehotencoder&#x27;,\n                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n                                 [&#x27;ChestPain&#x27;, &#x27;Thal&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>standardscaler</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Age&#x27;, &#x27;RestBP&#x27;, &#x27;Chol&#x27;, &#x27;RestECG&#x27;, &#x27;MaxHR&#x27;, &#x27;Oldpeak&#x27;, &#x27;Slope&#x27;, &#x27;Ca&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Sex&#x27;, &#x27;Fbs&#x27;, &#x27;ExAng&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>onehotencoder</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;ChestPain&#x27;, &#x27;Thal&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=1, max_features=2, n_estimators=200,\n                       random_state=2026)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n\n## Precision and recall cont'd\n\n- What do we think? Is this model ready for production in a diagnostic setting?\n\n- How could we improve it further?\n\n::: {#04b28fc9 .cell execution_count=18}\n``` {.python .cell-code}\ncv_results = pd.DataFrame(rf_tune_grid.cv_results_)\n\nmean_precision = cv_results['mean_test_precision'].iloc[rf_tune_grid.best_index_]\nsem_precision = cv_results['std_test_precision'].iloc[rf_tune_grid.best_index_] / np.sqrt(10)\nmean_recall = cv_results['mean_test_recall'].iloc[rf_tune_grid.best_index_]\nsem_recall = cv_results['std_test_recall'].iloc[rf_tune_grid.best_index_] / np.sqrt(10)\n\nresults_rf_tuned = pd.DataFrame({\n    'mean': [rf_tune_grid.best_score_, mean_precision, mean_recall],\n    'sem': [cv_results['std_test_accuracy'].iloc[rf_tune_grid.best_index_] / np.sqrt(10), sem_precision, sem_recall],\n}, index=['accuracy', 'precision', 'recall'])\n\nresults_rf_tuned\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy</th>\n      <td>0.860688</td>\n      <td>0.018576</td>\n    </tr>\n    <tr>\n      <th>precision</th>\n      <td>0.920505</td>\n      <td>0.022982</td>\n    </tr>\n    <tr>\n      <th>recall</th>\n      <td>0.770909</td>\n      <td>0.038928</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Feature importances\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n**Key points:**\n\n- Decision trees are very interpretable (decision rules!), however in ensemble\n  models (e.g., Random Forest and Boosting) there are many trees -\n  individual decision rules are not as meaningful...\n\n- Instead, we can calculate feature importances as\n  the total decrease in impurity for all splits involving that feature,\n  weighted by the number of samples involved in those splits,\n  normalized and averaged over all the trees.\n\n- These are calculated on the training set,\n  as that is the set the model is trained on.\n\n:::\n\n::: {.column width=\"50%\"}\n\n**Notes of caution!**\n\n- Feature importances can be unreliable with both highly cardinal,\n  and multicollinear features.\n\n- Unlike the linear model coefficients, feature importances do not have a sign!\n  They tell us about importance, but not an “up or down”.\n\n- Increasing a feature may cause the prediction to first go up, and then go down.\n\n- Alternatives to feature importance to understanding models exist\n  (e.g., [SHAP](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html)\n  (SHapley Additive exPlanations))\n\n:::\n::::\n\n## Feature importances in `scikit-learn`\n\n::: {#3d948b93 .cell execution_count=19}\n``` {.python .cell-code}\n# Access the best pipeline\nbest_pipeline = rf_tune_grid.best_estimator_\n\n# Extract the trained RandomForestClassifier from the pipeline\nbest_rf = best_pipeline.named_steps['randomforestclassifier']\n\n# Extract feature names after preprocessing\n# Get the names of features from each transformer in the pipeline\nnumeric_features = numeric_feats\ncategorical_feature_names = best_pipeline.named_steps['columntransformer'].transformers_[2][1].get_feature_names_out(categorical_feats)\npassthrough_features = passthrough_feats\n\n# Combine all feature names into a single list\nfeature_names = np.concatenate([numeric_features, passthrough_features, categorical_feature_names])\n\n# Calculate feature importances\nfeature_importances = best_rf.feature_importances_\n\n# Create a DataFrame to display feature importances\nimportances_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': feature_importances\n})\n\n# Sort by importance (descending order)\nimportances_df = importances_df.sort_values(by='Importance', ascending=False)\n```\n:::\n\n\n## Visualizing the results\n\n::: {#eba6146a .cell execution_count=20}\n\n::: {.cell-output .cell-output-display execution_count=20}\n```{=html}\n\n<style>\n  #altair-viz-2275cb648fe042a399188b38b3295b67.vega-embed {\n    width: 100%;\n    display: flex;\n  }\n\n  #altair-viz-2275cb648fe042a399188b38b3295b67.vega-embed details,\n  #altair-viz-2275cb648fe042a399188b38b3295b67.vega-embed details summary {\n    position: relative;\n  }\n</style>\n<div id=\"altair-viz-2275cb648fe042a399188b38b3295b67\"></div>\n<script type=\"text/javascript\">\n  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-2275cb648fe042a399188b38b3295b67\") {\n      outputDiv = document.getElementById(\"altair-viz-2275cb648fe042a399188b38b3295b67\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n    };\n\n    function maybeLoadScript(lib, version) {\n      var key = `${lib.replace(\"-\", \"\")}_version`;\n      return (VEGA_DEBUG[key] == version) ?\n        Promise.resolve(paths[lib]) :\n        new Promise(function(resolve, reject) {\n          var s = document.createElement('script');\n          document.getElementsByTagName(\"head\")[0].appendChild(s);\n          s.async = true;\n          s.onload = () => {\n            VEGA_DEBUG[key] = version;\n            return resolve(paths[lib]);\n          };\n          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n          s.src = paths[lib];\n        });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else {\n      maybeLoadScript(\"vega\", \"5\")\n        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-b7063293ee1f462303d75897ee88f27a\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Feature\", \"type\": \"nominal\"}, {\"field\": \"Importance\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Importance\", \"title\": \"Feature Importance\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Feature\", \"sort\": \"-x\", \"title\": \"Feature\", \"type\": \"nominal\"}}, \"height\": 400, \"title\": \"Feature Importances from Random Forest Model\", \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-b7063293ee1f462303d75897ee88f27a\": [{\"Feature\": \"ChestPain_asymptomatic\", \"Importance\": 0.14}, {\"Feature\": \"ExAng\", \"Importance\": 0.11}, {\"Feature\": \"Ca\", \"Importance\": 0.105}, {\"Feature\": \"MaxHR\", \"Importance\": 0.09}, {\"Feature\": \"Thal_normal\", \"Importance\": 0.085}, {\"Feature\": \"Thal_reversable\", \"Importance\": 0.075}, {\"Feature\": \"Oldpeak\", \"Importance\": 0.065}, {\"Feature\": \"Slope\", \"Importance\": 0.065}, {\"Feature\": \"ChestPain_nontypical\", \"Importance\": 0.06}, {\"Feature\": \"Age\", \"Importance\": 0.045}, {\"Feature\": \"Chol\", \"Importance\": 0.04}, {\"Feature\": \"RestBP\", \"Importance\": 0.035}, {\"Feature\": \"Sex\", \"Importance\": 0.035}, {\"Feature\": \"ChestPain_nonanginal\", \"Importance\": 0.02}, {\"Feature\": \"RestECG\", \"Importance\": 0.015}, {\"Feature\": \"ChestPain_typical\", \"Importance\": 0.015}, {\"Feature\": \"Thal_fixed\", \"Importance\": 0.0}, {\"Feature\": \"Fbs\", \"Importance\": 0.0}]}}, {\"mode\": \"vega-lite\"});\n</script>\n```\n:::\n:::\n\n\n## Evaluating on the test set\n\nPredict on the test set:\n\n::: {#ccd447ad .cell execution_count=21}\n``` {.python .cell-code}\nheart_test_drop_na = heart_test.dropna()\nX_test_drop_na = heart_test_drop_na.drop(columns=['AHD'])\ny_test_drop_na = heart_test_drop_na['AHD']\n\nheart_test_drop_na[\"predicted\"] = rf_tune_grid.predict(\n    X_test_drop_na\n)\n```\n:::\n\n\n## Evaluating on the test set\n\nExamine accuracy, precision and recall:\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {#7d55aa0c .cell execution_count=22}\n``` {.python .cell-code}\nrf_tune_grid.score(\n    X_test_drop_na,\n    y_test_drop_na\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\n0.7868852459016393\n```\n:::\n:::\n\n\n::: {#131bee80 .cell execution_count=23}\n``` {.python .cell-code}\nprecision_score(\n    y_true=heart_test_drop_na[\"AHD\"],\n    y_pred=heart_test_drop_na[\"predicted\"],\n    pos_label='Yes'\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\n0.8\n```\n:::\n:::\n\n\n::: {#6094be5f .cell execution_count=24}\n``` {.python .cell-code}\nrecall_score(\n    y_true=heart_test_drop_na[\"AHD\"],\n    y_pred=heart_test_drop_na[\"predicted\"],\n    pos_label='Yes'\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\n0.7142857142857143\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#9d158b27 .cell execution_count=25}\n``` {.python .cell-code}\nconf_matrix = pd.crosstab(\n    heart_test_drop_na[\"AHD\"],\n    heart_test_drop_na[\"predicted\"]\n)\nprint(conf_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npredicted  No  Yes\nAHD               \nNo         28    5\nYes         8   20\n```\n:::\n:::\n\n\n:::\n::::\n\n## Other boosting models:\n::: {.nonincremental}\n:::: {.columns}\n::: {.column width=\"50%\"}\n[XGBoost](https://lightgbm.readthedocs.io/)\n\n- Not part of `sklearn` but has similar interface.\n- Supports missing values\n- GPU training, networked parallel training\n- Supports sparse data\n- Typically better scores than random forests\n:::\n\n::: {.column width=\"50%\"}\n[LightGBM](https://lightgbm.readthedocs.io/)\n\n- Not part of sklearn but has similar interface.\n- Small model size\n- Faster\n- Typically better scores than random forests\n\n[CatBoost](https://catboost.ai/)\n\n- Not part of sklearn but has similar interface.\n- Usually better scores but slower compared to XGBoost and LightGBM\n:::\n::::\n:::\n\n## Keep learning!\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](img/frontmatter/ds-a-first-intro-cover-python.jpeg){height=50%}\n<https://python.datasciencebook.ca/>\n:::\n\n\n::: {.column width=\"50%\"}\n![](img/frontmatter/ISLP_cover.png){height=50%}\n<https://www.statlearning.com/>\n:::\n::::\n\n## Local installation\n\n1. Using Docker:\n[Data Science: A First Introduction (Python Edition) Installation Instructions](https://python.datasciencebook.ca/setup.html)\n\n2. Using conda:\n[UBC MDS Installation Instructions](https://ubc-mds.github.io/resources_pages/installation_instructions/)\n\n## Additional resources\n\n- The [UBC DSCI 573 (Feature and Model Selection notes)](https://ubc-mds.github.io/DSCI_573_feat-model-select)\n  chapter of Data Science: A First Introduction (Python Edition) by\n  Varada Kolhatkar and Joel Ostblom. These notes cover classification and regression metrics,\n  advanced variable selection and more on ensembles.\n- The [`scikit-learn` website](https://scikit-learn.org/stable/) is an excellent\n  reference for more details on, and advanced usage of, the functions and\n  packages in the past two chapters. Aside from that, it also offers many\n  useful [tutorials](https://scikit-learn.org/stable/tutorial/index.html)\n  to get you started.\n- [*An Introduction to Statistical Learning*](https://www.statlearning.com/) {cite:p}`james2013introduction` provides\n  a great next stop in the process of\n  learning about classification. Chapter 4 discusses additional basic techniques\n  for classification that we do not cover, such as logistic regression, linear\n  discriminant analysis, and naive Bayes.\n\n## References\n\nGareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani and Jonathan Taylor. An Introduction to Statistical Learning with Applications in Python. Springer, 1st edition, 2023. URL: https://www.statlearning.com/.\n\nKolhatkar, V., and Ostblom, J. (2024). UBC DSCI 573: Feature and Model Selection course notes. URL: https://ubc-mds.github.io/DSCI_573_feat-model-select\n\nPedregosa, F. et al., 2011. Scikit-learn: Machine learning in Python. Journal of machine learning research, 12(Oct), pp.2825–2830.\n\n",
    "supporting": [
      "ensembles_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}